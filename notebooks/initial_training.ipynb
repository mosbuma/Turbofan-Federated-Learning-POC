{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DGFrBsJOs8N6"
   },
   "source": [
    "# Turbofan POC - Initial Training and Model Serving\n",
    "\n",
    "This notebook is creating an initial model for predictions of the RUL for our turbofan engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teKaiaP8A-pN"
   },
   "source": [
    "## Imports and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26981,
     "status": "ok",
     "timestamp": 1582126813186,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "1Krj0J83x5O8",
    "outputId": "1b4a0cea-c47e-41e9-82a2-9b816e3765e9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if we are inside google colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    # mount gdrive for importing the data\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    # change this path to your notebooks directory inside google drive\n",
    "    %cd /content/gdrive/My\\ Drive/dev/turbofan_poc/notebooks\n",
    "\n",
    "    # set tensorflow version\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N61mNrV80NVr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from amdex import *\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RICPXgLi0g0R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the data \n",
    "data_folder_path = '/localstorage-trainer/data'\n",
    "model_data_path = '/localstorage-trainer/models/train_data_initial.txt'\n",
    "\n",
    "train_data_path = os.path.join(data_folder_path, 'train_data_initial.txt')\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data.set_index('time_in_cycles')\n",
    "\n",
    "val_data_path = os.path.join(data_folder_path, 'test_data_val.txt')\n",
    "val_data = pd.read_csv(val_data_path)\n",
    "val_data.set_index('time_in_cycles')\n",
    "\n",
    "test_data_path = os.path.join(data_folder_path, 'test_data_test.txt')\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data.set_index('time_in_cycles')\n",
    "\n",
    "# retrieve the max cycles per engine: RUL\n",
    "train_rul = pd.DataFrame(train_data.groupby('engine_no')['time_in_cycles'].max()).reset_index()\n",
    "# merge the RULs into the training data\n",
    "train_rul.columns = ['engine_no', 'max']\n",
    "train_data = train_data.merge(train_rul, on=['engine_no'], how='left')\n",
    "# add the current RUL for every cycle\n",
    "train_data['RUL'] = train_data['max'] - train_data['time_in_cycles']\n",
    "train_data.drop('max', axis=1, inplace=True)\n",
    "\n",
    "# test and validation data already contains the RUL values\n",
    "\n",
    "# drop the columns not needed\n",
    "cols_nan = train_data.columns[train_data.isna().any()].tolist()\n",
    "cols_const = [ col for col in train_data.columns if len(train_data[col].unique()) <= 2 ]\n",
    "\n",
    "# The operational settings 1 and 2 donÂ´t have a trend and they look like random noise.\n",
    "# Sensors 11, 12, 13 could be removed due to high correlations but it should be tested.\n",
    "# The trend of sensors 9 and 14 depend on the specific engine. Some engines at the end\n",
    "# of life tend to increase while others tend to decrease. What is common about these\n",
    "# two sensors is that the magnitude at the end life gets amplified. We should try\n",
    "# removing both sensors.\n",
    "cols_irrelevant = ['operational_setting_1', 'operational_setting_2', 'sensor_measurement_11', 'sensor_measurement_12', 'sensor_measurement_13']\n",
    "\n",
    "# Drop the columns without or with constant data\n",
    "train_data = train_data.drop(columns=cols_const + cols_nan + cols_irrelevant)\n",
    "val_data = val_data.drop(columns=cols_const + cols_nan + cols_irrelevant)\n",
    "test_data = test_data.drop(columns=cols_const + cols_nan + cols_irrelevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S58onfDNdAmc",
    "tags": []
   },
   "source": [
    "## Permission Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S58onfDNdAmc"
   },
   "source": [
    "<!-- permission = amdex.training_can_be_executed(userid, datasets[], 'algo description')\n",
    "if(permission):\n",
    "    print(\"training can proceed\")\n",
    "else:\n",
    "    print(\"permission denied\") -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S58onfDNdAmc"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvj4QbzCXZCT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the columns for training\n",
    "train_data_inputs = train_data.copy()\n",
    "train_data_inputs.drop(columns=['RUL', 'engine_no', 'time_in_cycles'], inplace=True)\n",
    "training_columns = train_data_inputs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lQGejNWjwWO"
   },
   "source": [
    "### Windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KLyLG86M0Ffn"
   },
   "source": [
    "To do our model training we split the data from an engine into rolling windows so we have the dimensions (total number of rows, time steps per window, feature columns).\n",
    "\n",
    "*Engine x for window size 3:*\n",
    "\n",
    "```\n",
    "[1 2 3 4 5 6] -> [1 2 3], [2 3 4], [3 4 5], [4 5 6]\n",
    "```\n",
    "\n",
    "As labels we pick the RUL of the last value in the windowed sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vt4z-bc_0Yr1"
   },
   "source": [
    "By splitting the data into windows we have to drop data samples that are smaller than the window size. This especially means we can not predict RUL values for smaller time series of engine data. An alternative would be to pad sequences so that we can use shorter ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6hSngDtXC-f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 80\n",
    "BATCH_SIZE = 210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWz7of5dXSr8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_to_windowed_data(dataset, window_size, window_limit = 0, verbose = True):\n",
    "  \"\"\"Transform the dataset into input windows with a label.\n",
    "\n",
    "  Args:\n",
    "      dataset (DataFrame): The dataset to tranform.\n",
    "      window_size (int): The length of the windows to create.\n",
    "      window_limit (int): The max windows to create for a data subset.\n",
    "\n",
    "  Returns:\n",
    "      (numpy.array, numpy.array): A tuple of features and labels.\n",
    "  \"\"\"\n",
    "  features = []\n",
    "  labels = []\n",
    "\n",
    "  dataset = dataset.set_index('time_in_cycles')\n",
    "  data_per_engine = dataset.groupby('engine_no')\n",
    "\n",
    "  for engine_no, engine_data in data_per_engine:\n",
    "      # skip if the engines cycles are too few\n",
    "      if len(engine_data) < window_size + window_limit -1:\n",
    "        continue\n",
    "\n",
    "      if window_limit != 0:\n",
    "        window_count = window_limit\n",
    "      else:\n",
    "        window_count = len(engine_data) - window_size\n",
    "\n",
    "      for i in range(0, window_count):\n",
    "        # take the last x cycles where x is the window size\n",
    "        start = -window_size - i\n",
    "        end = len(engine_data) - i\n",
    "        inputs = engine_data.iloc[start:end]\n",
    "        # use the RUL of the last cycle as label\n",
    "        outputs = engine_data.iloc[end - 1, -1]\n",
    "\n",
    "        inputs = inputs.drop(['engine_no', 'RUL'], axis=1)\n",
    "\n",
    "        features.append(inputs.values)\n",
    "        labels.append(outputs)\n",
    "\n",
    "  features = np.array(features)\n",
    "  labels = np.array(labels)\n",
    "  labels = np.expand_dims(labels, axis=1)\n",
    "\n",
    "  if verbose:\n",
    "    print(\"{} features with shape {}\".format(len(features), features[0].shape))\n",
    "    print(\"{} labels with shape {}\".format(len(labels), labels.shape))\n",
    "\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41696,
     "status": "ok",
     "timestamp": 1582126828101,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "NZR_quyYaept",
    "outputId": "771aa845-d484-4225-ff52-36388f5e166e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train = transform_to_windowed_data(train_data, WINDOW_SIZE)\n",
    "x_val, y_val = transform_to_windowed_data(val_data, WINDOW_SIZE)\n",
    "x_test, y_test = transform_to_windowed_data(test_data, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQV2DnpgddIq"
   },
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gi5NG6Vfw-yW"
   },
   "source": [
    "The data scaling will be embedded in the model so it could be easily applied to inference as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HP84vJPW2m0I"
   },
   "source": [
    "### Response Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IaMkCZCH2zpV"
   },
   "source": [
    "Since the degradation in a system will generally remain negligible until after some period of operation time the early and higher RUL values are probably unreasonable. We could tackle this by clipping the RUL values.\n",
    "\n",
    "That means we are fine with our model not correctly predicting RUL values above the *rul_clip_limit*. The model will still correctly identify that these engines but it is kind of cheating as the error for these engines improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qsK2hp6w2uLj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clip RUL values\n",
    "rul_clip_limit = 110\n",
    "\n",
    "y_train = y_train.clip(max=rul_clip_limit)\n",
    "y_val = y_val.clip(max=rul_clip_limit)\n",
    "y_test = y_test.clip(max=rul_clip_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh2YaxoKsHiB"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9dwxhK5a0i6"
   },
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hREayPLsHGzA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RMSE implementation\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(((y_true - y_pred) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YgTLRF4avmo"
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geHwiNH1LmE4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TurbofanModel(nn.Module):\n",
    "    def __init__(self, train_mean, train_std):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_mean = train_mean\n",
    "        self.train_std = train_std\n",
    "\n",
    "        self.fc1 = nn.Linear(len(training_columns), 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.fc3 = nn.Linear(24, 24)\n",
    "        self.fc4 = nn.Linear(24, 1)\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.train_mean = self.train_mean.to(device)\n",
    "        self.train_std = self.train_std.to(device)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # scale the input\n",
    "        x = (x - self.train_mean) / self.train_std\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WSJfEvrZdUwD"
   },
   "source": [
    "### Prepare Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmkrWZgRfxQ1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x_train = torch.Tensor(x_train)\n",
    "tensor_y_train = torch.Tensor(y_train)\n",
    "tensor_x_val = torch.Tensor(x_val)\n",
    "tensor_y_val = torch.Tensor(y_val)\n",
    "tensor_x_test = torch.Tensor(x_test)\n",
    "tensor_y_test = torch.Tensor(y_test)\n",
    "\n",
    "# create datasets for train, test and validation\n",
    "train_dataset = torch.utils.data.TensorDataset(tensor_x_train, tensor_y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(tensor_x_val, tensor_y_val)\n",
    "test_dataset = torch.utils.data.TensorDataset(tensor_x_test, tensor_y_test)\n",
    "\n",
    "# create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mBCUoRAZd4ZE"
   },
   "source": [
    "### Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KvrLlKWgLp2u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1ANRoq_JRF8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += criterion(output, target).item() * data.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66010,
     "status": "ok",
     "timestamp": 1582126852618,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "lqghpzITGwnd",
    "outputId": "248bc826-8389-44dc-d2b5-d565f913ceb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(51)\n",
    "\n",
    "epochs = 280\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "mean = tensor_x_train.mean(0)\n",
    "std = tensor_x_train.std(0)\n",
    "model = TurbofanModel(mean, std).to(device)\n",
    "\n",
    "criterion = nn.L1Loss() # mae\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "history = {}\n",
    "history['epoch'] = []\n",
    "history['loss'] = []\n",
    "history['val_loss'] = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "    val_loss = test(model, device, val_loader, criterion)\n",
    "\n",
    "    print('Epoch: {}/{}\\tloss: {:.4f}\\tval_loss: {:.4f}'.format(epoch, epochs, train_loss, val_loss))\n",
    "\n",
    "    history['epoch'].append(epoch)\n",
    "    history['loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66488,
     "status": "ok",
     "timestamp": 1582126853128,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "Ygq-M1r_RLOT",
    "outputId": "615ad0e5-1445-44ec-beba-34bfc5b08eea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(history['epoch'], np.array(history['loss']), label='Train Loss')\n",
    "plt.plot(history['epoch'], np.array(history['val_loss']), label = 'Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKzWYHzmUX-C"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67746,
     "status": "ok",
     "timestamp": 1582126854416,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "7OcTYtNhEizF",
    "outputId": "17a34af8-bab4-4d22-ced6-e18dab2d7db6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_res(model, test_data, test_labels, val_data, val_labels, train_data, train_labels):\n",
    "    output_test = model(test_data).to('cpu')\n",
    "    rmse_test = root_mean_squared_error(test_labels, output_test)\n",
    "    output_val = model(val_data).to('cpu')\n",
    "    rmse_val = root_mean_squared_error(val_labels, output_val)\n",
    "    output_train = model(train_data).to('cpu')\n",
    "    rmse_train = root_mean_squared_error(train_labels, output_train)\n",
    "    print(\"Testing set RMSE:  {:7.2f}\".format(rmse_test))\n",
    "    print(\"Validation set RMSE: {:7.2f}\".format(rmse_val))\n",
    "    print(\"Training set RMSE: {:7.2f}\".format(rmse_train))\n",
    "\n",
    "    test_predictions = output_test.flatten()\n",
    "    val_predictions = output_val.flatten()\n",
    "    train_predictions = output_train.flatten()\n",
    "\n",
    "    sns.displot(train_predictions - train_labels.flatten(), label=\"Train\", kde=True)\n",
    "    sns.displot(val_predictions - val_labels.flatten(), label=\"Val\", kde=True)\n",
    "    sns.displot(test_predictions - test_labels.flatten(), label=\"Test\", kde=True)\n",
    "\n",
    "    plt.xlabel(\"Prediction Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "tensor_x_train, tensor_x_val, tensor_x_test = tensor_x_train.to(device), tensor_x_val.to(device), tensor_x_test.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    plot_res(model, tensor_x_test, tensor_y_test, tensor_x_val, tensor_y_val, tensor_x_train, tensor_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLq7_EO36swu"
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67727,
     "status": "ok",
     "timestamp": 1582126854419,
     "user": {
      "displayName": "Matthias Lau",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC6WRAXJoMqa4-OAv4EwNhkeeciSt5GDAExs2YBOg=s64",
      "userId": "11790472444495897059"
     },
     "user_tz": -60
    },
    "id": "o9BMgIO83MKE",
    "outputId": "7a69653e-cca2-41c0-f829-c186eb19f7d8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the model to use it for the federated trainer\n",
    "model_data+path=\"\"\n",
    "print(model_data_path, flush=True)\n",
    "torch.save(model.to('cpu'), model_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CdDev2Dy7sMc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Federated_Learning_PySyft_InitialTraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
